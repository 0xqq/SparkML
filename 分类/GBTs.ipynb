{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification\n",
    "The example below demonstrates how to load a LIBSVM data file, parse it as an RDD of LabeledPoint and then perform classification using Gradient-Boosted Trees with log loss. The test error is calculated to measure the algorithm accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error = 0.02702702702702703\n",
      "Learned classification GBT model:\n",
      "TreeEnsembleModel classifier with 3 trees\n",
      "\n",
      "  Tree 0:\n",
      "    If (feature 434 <= 0.0)\n",
      "     If (feature 99 <= 0.0)\n",
      "      Predict: -1.0\n",
      "     Else (feature 99 > 0.0)\n",
      "      Predict: 1.0\n",
      "    Else (feature 434 > 0.0)\n",
      "     Predict: 1.0\n",
      "  Tree 1:\n",
      "    If (feature 434 <= 0.0)\n",
      "     If (feature 352 <= 246.0)\n",
      "      If (feature 400 <= 9.0)\n",
      "       If (feature 124 <= 0.0)\n",
      "        Predict: -0.4768116880884702\n",
      "       Else (feature 124 > 0.0)\n",
      "        Predict: -0.4768116880884703\n",
      "      Else (feature 400 > 9.0)\n",
      "       Predict: -0.4768116880884703\n",
      "     Else (feature 352 > 246.0)\n",
      "      Predict: 0.4768116880884694\n",
      "    Else (feature 434 > 0.0)\n",
      "     If (feature 467 <= 28.0)\n",
      "      If (feature 518 <= 248.0)\n",
      "       Predict: 0.47681168808847024\n",
      "      Else (feature 518 > 248.0)\n",
      "       Predict: 0.47681168808847024\n",
      "     Else (feature 467 > 28.0)\n",
      "      Predict: 0.4768116880884712\n",
      "  Tree 2:\n",
      "    If (feature 434 <= 0.0)\n",
      "     If (feature 242 <= 0.0)\n",
      "      Predict: 0.4381935810427206\n",
      "     Else (feature 242 > 0.0)\n",
      "      Predict: -0.4381935810427206\n",
      "    Else (feature 434 > 0.0)\n",
      "     If (feature 178 <= 0.0)\n",
      "      If (feature 123 <= 0.0)\n",
      "       Predict: 0.4381935810427206\n",
      "      Else (feature 123 > 0.0)\n",
      "       If (feature 124 <= 252.0)\n",
      "        Predict: 0.4381935810427206\n",
      "       Else (feature 124 > 252.0)\n",
      "        Predict: 0.43819358104272055\n",
      "     Else (feature 178 > 0.0)\n",
      "      If (feature 97 <= 0.0)\n",
      "       Predict: 0.43819358104272044\n",
      "      Else (feature 97 > 0.0)\n",
      "       Predict: 0.43819358104272044\n",
      "\n"
     ]
    }
   ],
   "source": [
    "val PATH = \"file:///Users/lzz/work/SparkML/\"\n",
    "import org.apache.spark.mllib.tree.GradientBoostedTrees\n",
    "import org.apache.spark.mllib.tree.configuration.BoostingStrategy\n",
    "import org.apache.spark.mllib.tree.model.GradientBoostedTreesModel\n",
    "import org.apache.spark.mllib.util.MLUtils\n",
    "\n",
    "// Load and parse the data file.\n",
    "val data = MLUtils.loadLibSVMFile(sc, PATH + \"data/mllib/sample_libsvm_data.txt\")\n",
    "// Split the data into training and test sets (30% held out for testing)\n",
    "val splits = data.randomSplit(Array(0.7, 0.3))\n",
    "val (trainingData, testData) = (splits(0), splits(1))\n",
    "\n",
    "// Train a GradientBoostedTrees model.\n",
    "//  The defaultParams for Classification use LogLoss by default.\n",
    "val boostingStrategy = BoostingStrategy.defaultParams(\"Classification\")\n",
    "boostingStrategy.numIterations = 3 // Note: Use more iterations in practice.\n",
    "boostingStrategy.treeStrategy.numClasses = 2\n",
    "boostingStrategy.treeStrategy.maxDepth = 5\n",
    "//  Empty categoricalFeaturesInfo indicates all features are continuous.\n",
    "boostingStrategy.treeStrategy.categoricalFeaturesInfo = Map[Int, Int]()\n",
    "\n",
    "val model = GradientBoostedTrees.train(trainingData, boostingStrategy)\n",
    "\n",
    "// Evaluate model on test instances and compute test error\n",
    "val labelAndPreds = testData.map { point =>\n",
    "  val prediction = model.predict(point.features)\n",
    "  (point.label, prediction)\n",
    "}\n",
    "val testErr = labelAndPreds.filter(r => r._1 != r._2).count.toDouble / testData.count()\n",
    "println(\"Test Error = \" + testErr)\n",
    "println(\"Learned classification GBT model:\\n\" + model.toDebugString)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression\n",
    "The example below demonstrates how to load a LIBSVM data file, parse it as an RDD of LabeledPoint and then perform regression using Gradient-Boosted Trees with Squared Error as the loss. The Mean Squared Error (MSE) is computed at the end to evaluate goodness of fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Mean Squared Error = 0.13333333333333333\n",
      "Learned regression GBT model:\n",
      "TreeEnsembleModel regressor with 3 trees\n",
      "\n",
      "  Tree 0:\n",
      "    If (feature 405 <= 0.0)\n",
      "     If (feature 99 <= 0.0)\n",
      "      Predict: 0.0\n",
      "     Else (feature 99 > 0.0)\n",
      "      Predict: 1.0\n",
      "    Else (feature 405 > 0.0)\n",
      "     Predict: 1.0\n",
      "  Tree 1:\n",
      "    Predict: 0.0\n",
      "  Tree 2:\n",
      "    Predict: 0.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import org.apache.spark.mllib.tree.GradientBoostedTrees\n",
    "import org.apache.spark.mllib.tree.configuration.BoostingStrategy\n",
    "import org.apache.spark.mllib.tree.model.GradientBoostedTreesModel\n",
    "import org.apache.spark.mllib.util.MLUtils\n",
    "\n",
    "// Load and parse the data file.\n",
    "val data = MLUtils.loadLibSVMFile(sc, PATH+\"data/mllib/sample_libsvm_data.txt\")\n",
    "// Split the data into training and test sets (30% held out for testing)\n",
    "val splits = data.randomSplit(Array(0.7, 0.3))\n",
    "val (trainingData, testData) = (splits(0), splits(1))\n",
    "\n",
    "// Train a GradientBoostedTrees model.\n",
    "//  The defaultParams for Regression use SquaredError by default.\n",
    "val boostingStrategy = BoostingStrategy.defaultParams(\"Regression\")\n",
    "boostingStrategy.numIterations = 3 // Note: Use more iterations in practice.\n",
    "boostingStrategy.treeStrategy.maxDepth = 5\n",
    "//  Empty categoricalFeaturesInfo indicates all features are continuous.\n",
    "boostingStrategy.treeStrategy.categoricalFeaturesInfo = Map[Int, Int]()\n",
    "\n",
    "val model = GradientBoostedTrees.train(trainingData, boostingStrategy)\n",
    "\n",
    "// Evaluate model on test instances and compute test error\n",
    "val labelsAndPredictions = testData.map { point =>\n",
    "  val prediction = model.predict(point.features)\n",
    "  (point.label, prediction)\n",
    "}\n",
    "val testMSE = labelsAndPredictions.map{ case(v, p) => math.pow((v - p), 2)}.mean()\n",
    "println(\"Test Mean Squared Error = \" + testMSE)\n",
    "println(\"Learned regression GBT model:\\n\" + model.toDebugString)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Spark 1.5.2 (Scala 2.10)",
   "language": "",
   "name": "spark"
  },
  "language_info": {
   "name": "scala",
   "version": "2.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
