{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Support Vector Machines (SVMs)\n",
    "线性SVM是一个标准的大型分类任务，它是一种$ \\begin{equation}\n",
    "    f(v) := \\lambda\\, R(w) +\n",
    "    \\frac1n \\sum_{i=1}^n L(v;x_i,y_i)\n",
    "    \\label{eq:regPrimal}\n",
    "    \\ .\n",
    "\\end{equation} $ 的线性模型，损失函数如下：\n",
    "$$L(w;x,y) := \\max \\{0, 1-y w^T x \\}.$$ \n",
    "默认情况下SVM使用的是L2正则化，我们也可以设置成L1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Area under ROC = 1.0\n"
     ]
    }
   ],
   "source": [
    "val PATH = \"file:///Users/lzz/work/SparkML/\"\n",
    "import org.apache.spark.mllib.classification.{SVMModel, SVMWithSGD}\n",
    "import org.apache.spark.mllib.evaluation.BinaryClassificationMetrics\n",
    "import org.apache.spark.mllib.util.MLUtils\n",
    "\n",
    "// Load training data in LIBSVM format.\n",
    "val data = MLUtils.loadLibSVMFile(sc, PATH+\"data/mllib/sample_libsvm_data.txt\")\n",
    "\n",
    "// Split data into training (60%) and test (40%).\n",
    "val splits = data.randomSplit(Array(0.6, 0.4), seed = 11L)\n",
    "val training = splits(0).cache()\n",
    "val test = splits(1)\n",
    "\n",
    "// Run training algorithm to build the model\n",
    "val numIterations = 100\n",
    "val model = SVMWithSGD.train(training, numIterations)\n",
    "\n",
    "// Clear the default threshold.\n",
    "model.clearThreshold()\n",
    "\n",
    "// Compute raw scores on the test set.\n",
    "val scoreAndLabels = test.map { point =>\n",
    "  val score = model.predict(point.features)\n",
    "  (score, point.label)\n",
    "}\n",
    "\n",
    "// Get evaluation metrics.\n",
    "val metrics = new BinaryClassificationMetrics(scoreAndLabels)\n",
    "val auROC = metrics.areaUnderROC()\n",
    "\n",
    "println(\"Area under ROC = \" + auROC)\n",
    "\n",
    "// Save and load model\n",
    "model.save(sc, \"myModelPath\")\n",
    "val sameModel = SVMModel.load(sc, \"myModelPath\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The SVMWithSGD.train() method by default performs L2 regularization with the regularization parameter set to 1.0. If we want to configure this algorithm, we can customize SVMWithSGD further by creating a new object directly and calling setter methods. All other MLlib algorithms support customization in this way as well. For example, the following code produces an L1 regularized variant of SVMs with regularization parameter set to 0.1, and runs the training algorithm for 200 iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import org.apache.spark.mllib.optimization.L1Updater\n",
    "\n",
    "val svmAlg = new SVMWithSGD()\n",
    "svmAlg.optimizer.\n",
    "  setNumIterations(200).\n",
    "  setRegParam(0.1).\n",
    "  setUpdater(new L1Updater)\n",
    "val modelL1 = svmAlg.run(training)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Spark 1.5.2 (Scala 2.10)",
   "language": "",
   "name": "spark"
  },
  "language_info": {
   "name": "scala",
   "version": "2.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
