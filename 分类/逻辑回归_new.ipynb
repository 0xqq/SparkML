{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 逻辑回归（Logistic regression）\n",
    "In MLlib, we implement popular linear methods such as logistic regression and linear least squares with L1L1 or L2L2 regularization. Refer to the linear methods in mllib for details. In spark.ml, we also include Pipelines API for Elastic net, a hybrid of L1L1 and L2L2 regularization proposed in Zou et al, Regularization and variable selection via the elastic net. Mathematically, it is defined as a convex combination of the L1L1 and the L2L2 regularization terms:\n",
    "在MLlib中我们实现了流行的线性方法像逻辑回归 通过L1或L2正则化的最小二乘法，spark.ml中提供了详细的线性方法\n",
    "逻辑回归是一种流行的二分类的方法。是一个特殊的广义线性模型预测的结果的概率。有关更多的背景和更多细节的实现，参考文献logistic regression in spark.mllib.  \n",
    "\n",
    "> 在spark.ml 逻辑回归当前只实现支持二分类。未来将增加多类回归支持。  \n",
    "\n",
    ">When fitting LogisticRegressionModel without intercept on dataset with constant nonzero column, Spark MLlib outputs zero coefficients for constant nonzero columns. This behavior is the same as R glmnet but different from LIBSVM.  \n",
    "\n",
    "## 例子\n",
    "下面的例子通过elastic net 和正则化训练逻辑回归模型，elasticNetParam 对应的是α regParam对应的是λ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights: (692,[244,263,272,300,301,328,350,351,378,379,405,406,407,428,433,434,455,456,461,462,483,484,489,490,496,511,512,517,539,540,568],[-7.353983524188245E-5,-9.102738505589519E-5,-1.9467430546904612E-4,-2.0300642473487006E-4,-3.147618331486081E-5,-6.842977602660782E-5,1.5883626898246297E-5,1.4023497091376187E-5,3.543204752496839E-4,1.1443272898171345E-4,1.0016712383667136E-4,6.014109303795461E-4,2.840248179122746E-4,-1.1541084736508883E-4,3.859968863129012E-4,6.350195574241052E-4,-1.1506412384575748E-4,-1.5271865864986881E-4,2.8049338089941963E-4,6.070117471191622E-4,-2.0084596632474579E-4,-1.4210755792901366E-4,2.739010341160868E-4,2.773045624496799E-4,-9.8380270272694E-5,-3.8085224435179237E-4,-2.5315198008556106E-4,2.774771477075417E-4,-2.443619763919299E-4,-0.001539474468759762,-2.307332841133226E-4]) Intercept: 0.22456315961250506\n"
     ]
    }
   ],
   "source": [
    "val PATH = \"file:///Users/lzz/work/SparkML/\"\n",
    "import org.apache.spark.ml.classification.LogisticRegression\n",
    "import org.apache.spark.mllib.util.MLUtils\n",
    "\n",
    "// 如果没有引入implictis那么toDF函数将不能工作\n",
    "val sqlContext= new org.apache.spark.sql.SQLContext(sc)\n",
    "  import sqlContext.implicits._\n",
    "    \n",
    "// 加载数据集成dataFrame\n",
    "val training = MLUtils.loadLibSVMFile(sc, PATH+\"data/mllib/sample_libsvm_data.txt\").toDF()\n",
    "\n",
    "val lr = new LogisticRegression().setMaxIter(10).setRegParam(0.3).setElasticNetParam(0.8)\n",
    "\n",
    "// 模型训练\n",
    "val lrModel = lr.fit(training)\n",
    "\n",
    "// 打印逻辑回归的权重和截距\n",
    "println(s\"Weights: ${lrModel.weights} Intercept: ${lrModel.intercept}\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Spark 1.5.2 (Scala 2.10)",
   "language": "",
   "name": "spark"
  },
  "language_info": {
   "name": "scala",
   "version": "2.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
